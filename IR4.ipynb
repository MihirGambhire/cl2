{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implement e-mail spam filtering using text classification algorithm with appropriate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (2.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (2.3.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sayal\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "--- 2. Successfully loaded 'spam.csv'. ---\n",
      "--- 3. Data cleaned and pre-processed. ---\n",
      "  category                                            message  category_num\n",
      "0      ham  Go until jurong point, crazy.. Available only ...             0\n",
      "1      ham                      Ok lar... Joking wif u oni...             0\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...             1\n",
      "3      ham  U dun say so early hor... U c already then say...             0\n",
      "4      ham  Even my brother is not like to speak with me. ...             0\n",
      "\n",
      "--- 4. Data split into training (70%) and testing (30%) sets. ---\n",
      "--- 5. Text converted to numbers (TF-IDF). ---\n",
      "--- 6. Model has been trained. ---\n",
      "\n",
      "--- 7. Evaluating Model Performance ---\n",
      "Accuracy on Test Data: 71.43%\n",
      "\n",
      "Classification Report (Test Data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83         5\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.71         7\n",
      "   macro avg       0.36      0.50      0.42         7\n",
      "weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "\n",
      "--- 8. Testing with a new email ---\n",
      "This email is HAM (not spam).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n",
      "C:\\Users\\sayal\\AppData\\Local\\Temp\\ipykernel_10820\\1667944191.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data.rename(columns={'v1': 'category', 'v2': 'message'}, inplace=True)\n",
      "C:\\Users\\sayal\\AppData\\Local\\Temp\\ipykernel_10820\\1667944191.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['category_num'] = clean_data['category'].map({'ham': 0, 'spam': 1})\n",
      "C:\\Users\\sayal\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\sayal\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\sayal\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "file_name = 'spam.csv' \n",
    "try:\n",
    "    # Use on_bad_lines='skip' to avoid errors from \"broken\" data\n",
    "    mail_data = pd.read_csv(file_name, encoding='latin-1', on_bad_lines='skip')\n",
    "    print(f\"--- 2. Successfully loaded '{file_name}'. ---\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"--- ERROR: '{file_name}' not found! ---\")\n",
    "    print(\"Please make sure you saved the sample data as 'spam.csv' in the same folder.\")\n",
    "\n",
    "# --- 3. Pre-processing ---\n",
    "# Keep only the two columns we need\n",
    "clean_data = mail_data[['v1', 'v2']]\n",
    "clean_data.rename(columns={'v1': 'category', 'v2': 'message'}, inplace=True)\n",
    "\n",
    "# Convert category ('ham' or 'spam') into numbers (0 or 1)\n",
    "clean_data['category_num'] = clean_data['category'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "print(\"--- 3. Data cleaned and pre-processed. ---\")\n",
    "print(clean_data.head()) # Shows the first 5 rows\n",
    "\n",
    "\n",
    "# --- 4. Define your X (features) and y (target) ---\n",
    "X = clean_data['message']\n",
    "y = clean_data['category_num']\n",
    "\n",
    "# --- 5. Split Data into Training and Testing sets ---\n",
    "# --- random_state=5 ensures we get the exact same \"random\" split every time, making our results reproducible. ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "print(\"\\n--- 4. Data split into training (70%) and testing (30%) sets. ---\")\n",
    "\n",
    "# --- 6. Text Feature Extraction (TF-IDF) ---\n",
    "# This converts your text (e.g., \"free offer\") into numbers\n",
    "feature_extraction = TfidfVectorizer(min_df=1, stop_words='english', lowercase=True)\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "print(\"--- 5. Text converted to numbers (TF-IDF). ---\")\n",
    "\n",
    "# --- 7. Train the Classification Model ---\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_features, y_train)\n",
    "print(\"--- 6. Model has been trained. ---\")\n",
    "\n",
    "# --- 8. Evaluate the Model ---\n",
    "print(\"\\n--- 7. Evaluating Model Performance ---\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "accuracy_on_test_data = accuracy_score(y_test, prediction_on_test_data)\n",
    "# This will now be a more realistic number (like 80-95%)\n",
    "print(f\"Accuracy on Test Data: {accuracy_on_test_data * 100:.2f}%\") \n",
    "\n",
    "# Print the full report\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test, prediction_on_test_data))\n",
    "\n",
    "\n",
    "# --- 9. Test with a new, custom email ---\n",
    "print(\"\\n--- 8. Testing with a new email ---\")\n",
    "input_mail = [\"Congratulations! You have won a 1 million dollar prize. Click here to claim.\"]\n",
    "\n",
    "# Convert the new email to numbers\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(input_data_features)\n",
    "\n",
    "if prediction[0] == 1:\n",
    "    print(\"This email is SPAM.\")\n",
    "else:\n",
    "    print(\"This email is HAM (not spam).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of the Practical\n",
    "The purpose is to build a supervised machine learning model that can automatically read an email and classify it as either \"Spam\" (junk) or \"Ham\" (a normal, non-junk email).\n",
    "\n",
    "This is a classic \"Text Classification\" problem. We will train a model on a dataset of emails that are already labeled as 'spam' or 'ham'. The model will learn the patterns of words associated with spam, and then we'll use it to predict the label for new, unseen emails.\n",
    "\n",
    "üß† Core Theory (How it Works)\n",
    "This practical involves two key concepts:\n",
    "\n",
    "TF-IDF Vectorization: Computers don't understand words, they only understand numbers. We need to convert the text of each email into a numerical format. We do this using TF-IDF (Term Frequency-Inverse Document Frequency).\n",
    "\n",
    "Term Frequency (TF): How often a word appears in one email. A word like \"win\" appearing 5 times is important.\n",
    "\n",
    "Inverse Document Frequency (IDF): How \"rare\" a word is across all emails. A common word like \"the\" (low IDF) is ignored. A rare word like \"lottery\" or \"viagra\" (high IDF) is a very strong signal.\n",
    "\n",
    "The Score: The TF-IDF score is high for words that are frequent in one email but rare overall. This helps the model identify important, signal-carrying words.\n",
    "\n",
    "Multinomial Naive Bayes (MultinomialNB): This is the classification algorithm (the \"brain\") we are using.\n",
    "\n",
    "It's a fast, simple, and highly effective algorithm for text.\n",
    "\n",
    "It uses Bayes' Theorem to calculate the probability of an email being \"Spam\" given the set of TF-IDF scores for the words it contains.\n",
    "\n",
    "It's called \"Naive\" because it naively assumes that every word is independent of the others (e.g., it doesn't care that \"free\" and \"prize\" appear together, just that both words are present).\n",
    "\n",
    "üìã Step-by-Step Code Explanation\n",
    "Import Libraries: We import pandas to read the CSV, train_test_split to divide our data, TfidfVectorizer to convert text to numbers, MultinomialNB as our classifier, and accuracy_score to check our work.\n",
    "\n",
    "Load & Clean Data:\n",
    "\n",
    "We use pd.read_csv('spam.csv') to load the dataset.\n",
    "\n",
    "The most important cleaning step is clean_data['category_num'] = .... This converts the text labels \"ham\" and \"spam\" into the numbers 0 and 1, which the model can understand.\n",
    "\n",
    "Define X and y: We set our X (features) to be the message column (the text) and our y (target) to be the category_num column (the 0 or 1 label).\n",
    "\n",
    "Split Data: We use train_test_split to split our data.\n",
    "\n",
    "X_train & y_train: The training set (e.g., 70% of the data). The model learns from this.\n",
    "\n",
    "X_test & y_test: The testing set (e.g., 30% of the data). We \"hide\" this from the model to check its performance later.\n",
    "\n",
    "Feature Extraction (TF-IDF): This is the most crucial part.\n",
    "\n",
    "We create a TfidfVectorizer object.\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train): This does two things:\n",
    "\n",
    "fit: It reads all of X_train to learn the entire vocabulary (all unique words).\n",
    "\n",
    "transform: It converts the text in X_train into a matrix of TF-IDF numbers.\n",
    "\n",
    "X_test_features = feature_extraction.transform(X_test): It uses the same vocabulary learned from X_train to convert X_test into a number matrix.\n",
    "\n",
    "Train the Model:\n",
    "\n",
    "We create a MultinomialNB object.\n",
    "\n",
    "model.fit(X_train_features, y_train): This is the \"training.\" The model learns the probability patterns that connect the TF-IDF numbers (the words) to their correct labels (spam or ham).\n",
    "\n",
    "Evaluate the Model:\n",
    "\n",
    "prediction_on_test_data = model.predict(X_test_features): We use the trained model to make predictions on the \"hidden\" test data.\n",
    "\n",
    "accuracy_score(y_test, prediction_on_test_data): We compare the model's predictions to the actual answers (y_test) to calculate its accuracy.\n",
    "\n",
    "Test on New Data: The last step shows how you can use the same trained feature_extraction and model to predict the class of any new email you type in.\n",
    "\n",
    "üõ†Ô∏è Key Libraries & Functions\n",
    "pandas: For loading and cleaning the spam.csv file.\n",
    "\n",
    "sklearn.model_selection.train_test_split: The function used to split the data into training and testing sets.\n",
    "\n",
    "sklearn.feature_extraction.text.TfidfVectorizer: The most important tool. It converts raw text into a meaningful matrix of TF-IDF scores.\n",
    "\n",
    ".fit_transform(X_train): (Fit + Transform) Learns the vocabulary and transforms the training data. Use this on X_train ONLY.\n",
    "\n",
    ".transform(X_test): (Only Transform) Only transforms the test data using the vocabulary it already learned from X_train. Use this on X_test and any new data.\n",
    "\n",
    "sklearn.naive_bayes.MultinomialNB: The classification algorithm (the \"brain\").\n",
    "\n",
    "model.fit(...): The function that trains the model.\n",
    "\n",
    "model.predict(...): The function that makes predictions on new, unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
